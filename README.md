# 以自动文章生成任务演示如何使用Mengzi预训练模型

自动文摘的目的是通过对原文本进行压缩、提炼，为用户供简明扼要的文字描述。自动文摘是一个信息压缩过程，将输入的一篇或多篇文档内容总结为一段简要描述，该过程不可避免有信息损失，但是要求保留尽可能多的重要信息，自动文摘也是自然语言生成领域中一个重要任务。
下面我们以文本摘要任务为例，展示孟子预训练模型在下游任务上微调的流程，整体流程可以分为5部分：

- 数据加载
- 数据预处理
- 模型训练
- 模型推理
- 评测

下面我们以中文科学文献数据（CSL）文本摘要数据为例进行演示。

## 环境安装
代码使用以下环境运行
- torch==1.8.0
- transformers==4.12.5
- sentencepiece==0.1.95
- rouge==1.0.1
- nltk==3.6.5
- tqdm==4.65.0

## 数据集下载
数据下载地址：[https://github.com/CLUEbenchmark/CLGE](https://github.com/CLUEbenchmark/CLGE)，下载过后将数据解压放在项目根目录。

下载的原始数据：训练集(3,000)，验证集(500)，测试集(500)，但测试集没有摘要标注结果，所以这里我们简单地把验证集当作测试集，从训练集中划出500条作为开发集。

## 预训练模型下载
模型下载地址：[https://github.com/Langboat/Mengzi](https://github.com/Langboat/Mengzi)，下载过后将模型解压放在项目根目录。

## 数据集加载和模型的训练、验证
见example.py文件